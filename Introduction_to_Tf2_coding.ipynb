{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction_to_Tf2_coding.ipynb","provenance":[{"file_id":"17GbhFaf09MytGJdCzBYh4kWfdqdSvoE2","timestamp":1598085117728}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rV5KtxZglrLt"},"source":["**Tensorflow**\n","\n","*   Tensorflow is an open-sourse  deep learning library.\n","*   Tensorflow created by Google Brain Team.\n","\n","*   The main concern is high end efficient computing for different deep learning operation.\n","\n","**Keras**\n","\n","*   Keras is an open-source deep learning library.\n","*   Simple and clean interface. \n","\n","*   Allow deep learning mathematical libraries like Tensorflow as the backend.\n","\n","**Tensorflow - Keras**\n","\n","*   New version of TensorFlow (TensorFlow 2) Google integrate the Keras API directly and promoted this interface as the default interface.\n","*   Single library can now be used instead of two separate libraries.\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ClW5CkybuBtF"},"source":["**3 ways to create keras models in tensorflow 2.x**\n","\n","*   Sequential\n","*   Functional\n","*   Model Subclassing"]},{"cell_type":"markdown","metadata":{"id":"i2goxy8R5be_"},"source":["Machine learning architecture works mainly in four parts:\n","\n","    \n","\n","*   Preprocessing the data\n","*   Build the model\n","\n","\n","*   Compile the model.\n","\n","*   Train and estimate the model\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"7wWnQf7m24ba"},"source":["import tensorflow as tf\n","from tensorflow.keras import Model, activations\n","from tensorflow.keras.layers import Dense, Activation, Input\n","from tensorflow.keras.models import Sequential\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2c4Issq2yf9"},"source":["Import tensorflow prebuilt dataset Fashion_MNIST"]},{"cell_type":"code","metadata":{"id":"GiZjEbj8yVF_"},"source":["train,test = tf.keras.datasets.fashion_mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mgJ9C6O7uG3J"},"source":["We will use Fashion Mnist dataset.\n","contains 10 classes of grayscale fashion images.\n","\n","\n","0: T-shirt/top\n","1: Trouser\n","2: Pullover\n","3: Dress\n","4: Coat\n","5: Sandal\n","6: Shirt\n","7: Sneaker\n","8: Bag\n","9: Ankle boot"]},{"cell_type":"code","metadata":{"id":"6JtcDo8OthC9"},"source":["train_x = train[0]\n","train_y = train[1]\n","test_x = test[0]\n","test_y = test[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LOGK5NH5IRED"},"source":["print(train_x.shape)\n","print(train_y.shape)\n","print(train_y[0:10])\n","print(test_x.shape)\n","print(test_y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0W2lt7RB72gc"},"source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(15,15))\n","for i in range(25):\n","  plt.subplot(5,5,i+1)\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.imshow(train_x[i],cmap='Greys')\n","  plt.xlabel(i)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DykPh0bJ8IPT"},"source":["train_x = np.reshape(train_x,[60000,28*28])\n","test_x = np.reshape(test_x,[10000,28*28])\n","\n","train_y = tf.keras.utils.to_categorical(train_y)\n","test_y = tf.keras.utils.to_categorical(test_y)\n","\n","print(train_x.shape)\n","print(test_x.shape)\n","print(train_y.shape)\n","print(test_y.shape)\n","\n","train_x =train_x/ 255.\n","test_x = test_x/255."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nJeDmiUb8mdj"},"source":["**Tensorflow-Keras Sequential API**\n","\n","Keras Sequential API is by far the easiest way to get up and running with Keras, but it’s also the most limited \n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"13y_6Nyd9dxo"},"source":["def my_sequential_model(inp_dim, noc = 10):\n","  model = Sequential()\n","  model.add(Dense(input_dim = inp_dim, units= 50, name='dense-1', activation='relu'))\n","  model.add(Dense(units=50, name='dense-2', activation='relu'))\n","  model.add(Dense(units=noc, activation='softmax'))\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-hfyKijV_q-z"},"source":["my_model = my_sequential_model(len(train_x[0]))\n","base_learning_rate = 0.0001\n","my_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n","                      loss=tf.keras.losses.categorical_crossentropy,\n","                      metrics = ['accuracy'])\n","my_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CfhX0KWjT7se"},"source":["tf.keras.utils.plot_model(my_model,'my_model.png',show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pN-Kwy_x__Fx"},"source":["best_acc = 0\n","for e in range(20):\n","  history = my_model.fit(train_x, train_y, batch_size = 32, validation_data=(test_x,test_y), verbose=True, epochs=1)\n","  val_acc = history.history['val_accuracy'][0]\n","  if val_acc > best_acc:\n","    my_model.save('model_weights'+'.h5')\n","    best_acc = val_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vuT2h8sAPrCK"},"source":["my_model=tf.keras.models.load_model('model_weights.h5')\n","predictions = my_model.predict(test_x[0:10])\n","i=0\n","for sample in predictions:\n","  print(\"Original---->\",np.argmax(test_y[i]),\"Predictted---->\",np.argmax(sample))\n","  i +=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L7h7tfgOsKAz"},"source":["**Tensorflow-Keras Functional API**"]},{"cell_type":"markdown","metadata":{"id":"5FM2nnW1rKkA"},"source":["Using the Functional API you can:\n","\n","1. Create more complex models.\n","2. Have multiple inputs and multiple outputs.\n","3. Easily define branches in your architectures.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DxEtj39Q_B-j"},"source":["# Sequential connection\n","def my_functional_model(inp_shape, noc=10):\n","  inputs = Input(shape=inp_shape)  \n","  layer1 = Dense(units=50, name='dense-1')(inputs)\n","  act1= Activation('relu')(layer1)\n","  layer2 = Dense(units=50, name='dense-2')(act1)\n","  act2 = Activation('relu')(layer2)\n","  out_layer= Dense(noc, activation='softmax')(act2)\n","  model = Model(inputs=inputs, outputs=out_layer)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATKaiiYHN4i6"},"source":["'''\n","# Concatenate two intermediate layers\n","def my_functional_model(inp_shape, noc=10):\n","  inputs = Input(shape=inp_shape)\n","  layer1 = Dense(units=50, name='dense-1')(inputs)\n","  act1= Activation('relu')(layer1)\n","  layer2 = Dense(units=50, name='dense-2')(inputs)\n","  act2 = Activation('relu')(layer2)\n","  layer3 = tf.keras.layers.concatenate([act1,act2],axis=1)\n","  act3 = Activation('relu')(layer3) \n","  out_layer= Dense(noc, activation='softmax')(act3)\n","  model = Model(inputs=inputs, outputs=out_layer)\n","  return model\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IBBWcEo3WhiQ"},"source":["'''\n","# Add two intermediate layers\n","def my_functional_model(inp_shape, noc=10):\n","  inputs = Input(shape=inp_shape)  \n","  layer1 = Dense(units=50, name='dense-1')(inputs)\n","  act1= Activation('relu')(layer1)\n","  layer2 = Dense(units=50, name='dense-2')(inputs)\n","  act2 = Activation('relu')(layer2)\n","  layer3 = tf.keras.layers.add([act1,act2])\n","  act3 = Activation('relu')(layer3)\n","  out_layer= Dense(noc, activation='softmax')(act3)\n","  model = Model(inputs=inputs, outputs=out_layer)\n","  return model\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nuOntr3NPq3j"},"source":["print(train_x[0].shape)\n","my_model= my_functional_model(train_x[0].shape)\n","opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","l= tf.keras.losses.categorical_crossentropy\n","my_model.compile(optimizer=opt, loss=l, metrics=['accuracy'])\n","my_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"StqR4vG7UVs4"},"source":["tf.keras.utils.plot_model(my_model,'my_model.png',show_shapes=True,dpi=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mukWuXgdTEE0"},"source":["best_acc = 0\n","for e in range(20):\n","  history = my_model.fit(train_x, train_y, batch_size = 32, validation_data=(test_x,test_y), verbose=True, epochs=1)\n","  val_acc = history.history['val_accuracy'][0]\n","  if val_acc > best_acc:\n","    my_model.save('model_weights_func'+str(e)+'.h5')\n","    best_acc = val_acc\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MCwprNAqVRW"},"source":["my_model=tf.keras.models.load_model('model_weights_func18.h5')\n","predictions = my_model.predict(test_x[10:20])\n","i=10\n","for sample in predictions:\n","  print(\"Original---->\",np.argmax(test_y[i]),\"Predictted---->\",np.argmax(sample))\n","  i +=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"577RA0Xbui7g"},"source":["**Tensorflow-Keras Model Subclassing**\n","\n","Now we will build tensorflow model with Object oriented approach and overriding Model API"]},{"cell_type":"markdown","metadata":{"id":"R3i0QGsnvr3w"},"source":["Model subclassing is fully-customizable and enables you to implement your own custom forward-pass of the model.\n","\n","However, this flexibility and customization comes at a cost — model subclassing is way harder to utilize than the Sequential API or Functional API.\n","\n"]},{"cell_type":"code","metadata":{"id":"uYEId5btuuja"},"source":["class MLP(Model):\n","  def __init__(self, noc):\n","    super(MLP, self).__init__()\n","    self.noc = noc\n","    self.dense1 = Dense(50)\n","    self.dense2 = Dense(50)\n","    self.out = Dense(self.noc)\n","  def call(self, x):\n","    x = self.dense1(x)\n","    x = tf.nn.relu(x)\n","    x= self.dense2(x)\n","    x= tf.nn.relu(x)\n","    x= self.out(x)\n","    x = tf.nn.softmax(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fm1T-mBIzp8w"},"source":["model = MLP(noc =10)\n","optimizer = tf.optimizers.Adam(0.001)\n","ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n","manager = tf.train.CheckpointManager(ckpt, 'Weights', max_to_keep=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYk6ih-l0UPu"},"source":["def cross_entropy_loss(y_pred,y_true):\n","  y_true = tf.cast(y_true, tf.float64)\n","  loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n","  mn_loss= tf.reduce_mean(loss)\n","  return mn_loss\n","\n","def accuracy(y_pred, y_true):\n","  y_true = tf.cast(y_true, tf.float64)\n","  acc = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n","  #print(\"ACC------>\",acc)\n","  return tf.reduce_mean(tf.cast(acc, tf.float64))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qgxdOTr33XeB"},"source":["def batch_train(x, y):\n","    # Wrap computation inside a GradientTape for automatic differentiation.\n","    with tf.GradientTape() as g:\n","        # Forward pass.\n","        pred = model(x)\n","        # Compute loss.\n","        loss = cross_entropy_loss(pred, y)\n","\n","        # Variables to update, i.e. trainable variables.\n","        trainable_variables = model.trainable_variables\n","\n","        # Compute gradients.\n","        gradients = g.gradient(loss, trainable_variables)\n","\n","        # Update W and b following gradients.\n","        optimizer.apply_gradients(zip(gradients, trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhvO9Hhd5EXj"},"source":["# Run training for the given number of steps.\n","ckpt.restore(manager.latest_checkpoint)\n","if manager.latest_checkpoint:\n","  print(\"Restored from {}\".format(manager.latest_checkpoint))\n","else:\n","  print(\"Initializing from scratch.\")\n","\n","epochs= 10\n","batch_size = 32\n","l_train= len(train_x)\n","l_test = len(test_x)\n","max_acc = 0\n","\n","for e in range(epochs):\n","  avg_loss=0\n","  avg_acc=0\n","  batch_count=0\n","  start=0\n","  \n","\n","  while(start< l_train):\n","      # Run the optimization to update W and b values.\n","      if(start + batch_size < l_train):\n","        batch_x =  train_x[start : start + batch_size]\n","        batch_y = train_y[start : start + batch_size]\n","      else:\n","        batch_x = train_x[start : ]\n","        batch_y = train_y[start : ]\n","      \n","      batch_train(batch_x, batch_y)\n","      pred = model(batch_x)\n","      avg_loss+= cross_entropy_loss(pred, batch_y)\n","      avg_acc+= accuracy(pred, batch_y)\n","      batch_count+=1\n","      start += batch_size\n","      \n","      #print('Running Train Batch ',batch_count)\n","\n","  avg_loss/=batch_count\n","  avg_acc/=batch_count\n","  \n","  test_acc=0\n","  test_loss=0\n","  batch_count = 0 \n","  start = 0\n","  \n","  while(start< l_test):\n","      # Run the optimization to update W and b values.\n","      if(start + batch_size < l_test):\n","        batch_x =  test_x[start : start + batch_size]\n","        batch_y = test_y[start : start + batch_size]\n","      else:\n","        batch_x = test_x[start : ]\n","        batch_y = test_y[start :]\n","      \n","      #run_optimization(batch_x, batch_y)\n","      pred = model(batch_x)\n","      test_loss+= cross_entropy_loss(pred, batch_y)\n","      pred=tf.nn.softmax(pred)\n","      test_acc+= accuracy(pred, batch_y)\n","      batch_count+=1\n","      start += batch_size\n","      #print('Running Test Batch ',batch_count)\n","  \n","  avg_test_acc = test_acc / batch_count\n","  avg_test_loss = test_loss /batch_count\n","  if (avg_test_acc > max_acc):\n","    save_path = manager.save()\n","    print('Best Model saved at ',save_path)\n","    max_acc = avg_test_acc\n","    \n","  print(\"epoch: {0} , avg_Train_loss: {1}, avg_Train_acc: {2}, test loss {3}, test acc {4}\\n\\n\".format(e,avg_loss,avg_acc,avg_test_loss,avg_test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rDH8CjsVRpGr"},"source":["pred = model(test_x[10:20])\n","i=10\n","for sample in pred:\n","  print(\"Original---->\",np.argmax(test_y[i]),\"Predictted---->\",np.argmax(sample))\n","  i +=1"],"execution_count":null,"outputs":[]}]}